{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary completely loaded..\n"
     ]
    }
   ],
   "source": [
    "#Get data loader for test mode\n",
    "from data_set_loader import get_data_set_loader\n",
    "from torchvision import transforms\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize((224, 224)), \\\n",
    "                                     transforms.ToTensor(), \\\n",
    "                                     transforms.Normalize((0.485, 0.456, 0.406), \\\n",
    "                                                          (0.229, 0.224, 0.225))])\n",
    "\n",
    "data_set_loader = get_data_set_loader(transform=transform_test,    \n",
    "                         mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from pipeline_models import EncoderCNN, DecoderRNN\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#embedding size, number of hidden units and batch size\n",
    "embed_size = 512\n",
    "hidden_size = 512\n",
    "batch_size= 512\n",
    "\n",
    "#Size of the vocabulary created while training the CNN-RNN model\n",
    "vocab_size = len(data_set_loader.dataset.vocabulary)\n",
    "\n",
    "encoder = EncoderCNN(embed_size)\n",
    "encoder.eval()\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, batch_size)\n",
    "decoder.eval()\n",
    "\n",
    "# This file contains the captions for the test images. We will evaluate our model performance using these captions\n",
    "import json\n",
    "f = open('captions_val2014.json')\n",
    "original_data=json.load(f)\n",
    "\n",
    "#Each image has 5 captions. We will mantain a dictionary with key as image_id and list of 5 captions as values\n",
    "original_data_anns={}\n",
    "ann_list=original_data[\"annotations\"]\n",
    "for ele in ann_list:\n",
    "    cnt=12-len(str(ele[\"image_id\"]))\n",
    "    img_key=\"COCO_val2014_\"+'0'*cnt+str(ele[\"image_id\"])+\".jpg\"\n",
    "    if(img_key in original_data_anns.keys()):\n",
    "        original_data_anns[img_key].append(ele[\"caption\"])\n",
    "    else:\n",
    "        original_data_anns[img_key]=[ele[\"caption\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the words from vocabulary file using indices and then clean the sentence\n",
    "def clean_sentence(output):\n",
    "    word_list = []\n",
    "    \n",
    "    for index in output:\n",
    "        token=data_set_loader.dataset.vocabulary.idx2word[index]\n",
    "        word_list.append(token)\n",
    "    \n",
    "    word_list = word_list[1:-1]\n",
    "    output_sentence = ' '.join(word_list)\n",
    "    sentence = output_sentence.capitalize()\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate BLEU score for the model.\n",
    "def get_bleu_score(encoder_file,decoder_file):\n",
    "    #Load encoder and decoder models.\n",
    "    encoder.load_state_dict(torch.load(encoder_file,map_location=torch.device('cpu')))\n",
    "    decoder.load_state_dict(torch.load(decoder_file,map_location=torch.device('cpu')))\n",
    "\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    dir_src = (\"val2014/\")\n",
    "    predictions={}\n",
    "    #Get predictions for each image in the test set.\n",
    "    for filename in os.listdir(dir_src):\n",
    "        PIL_image = Image.open(dir_src + filename).convert('RGB')\n",
    "        orig_image = np.array(PIL_image)\n",
    "\n",
    "        #Transform the image\n",
    "        transform_test = transforms.Compose([transforms.Resize((224, 224)), \\\n",
    "                                            transforms.ToTensor(), \\\n",
    "                                            transforms.Normalize((0.485, 0.456, 0.406), \\\n",
    "                                                                (0.229, 0.224, 0.225))])\n",
    "\n",
    "        image = transform_test(PIL_image)\n",
    "        image = image.to(device)\n",
    "        image=torch.Tensor(image).unsqueeze(0)\n",
    "\n",
    "        #Get features from the encoder model.\n",
    "        features = encoder(image).unsqueeze(1)\n",
    "\n",
    "        #Get word tokens from decoder model.\n",
    "        output = decoder.sample(features)\n",
    "\n",
    "        #Get the text from word token indices    \n",
    "        sentence = clean_sentence(output)\n",
    "        predictions[filename]=sentence\n",
    "\n",
    "    from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
    "    references=[]\n",
    "    candidates=[]\n",
    "    #Format input original captions and predicted captions to calculate BLEU score.\n",
    "    for key in list(original_data_anns.keys()):\n",
    "        refs=original_data_anns[key]\n",
    "        refs_split=[]\n",
    "        for ref in refs:\n",
    "            refs_split.append(ref.split())\n",
    "        cand=predictions[key].split()\n",
    "        references.append(refs_split)\n",
    "        candidates.append(cand)\n",
    "    \n",
    "    #Calculating BLEU using unigrams\n",
    "    score=corpus_bleu(references,candidates,weights=(1,0,0,0))\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5927661081245713\n"
     ]
    }
   ],
   "source": [
    "get_bleu_score(\"encoderCNN.pkl\",\"decoderRNN.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
